{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "hw1p2.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZB8JUHXio47q"
      },
      "source": [
        "Здесь я обрабатываю данные, скачанные в hw1p1.py"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jpMon3ynE_zQ"
      },
      "source": [
        "!pip install nltk"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xD0Qd2RZGH3J"
      },
      "source": [
        "!pip install pymorphy2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y8ohiN2Nu_LF",
        "outputId": "4a080ec8-b142-44f0-bfb8-74aab072a570",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        }
      },
      "source": [
        "!pip install sklearn"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: sklearn in /usr/local/lib/python3.6/dist-packages (0.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from sklearn) (0.22.2.post1)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->sklearn) (1.4.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->sklearn) (0.16.0)\n",
            "Requirement already satisfied: numpy>=1.11.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->sklearn) (1.18.5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k2iiwq5KFGCA"
      },
      "source": [
        "import nltk"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N4CYsBysJofe",
        "outputId": "4821072e-00b7-42e6-eca6-d51008fcaeb4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "nltk.download('punkt')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jFGr9psMF6Gl"
      },
      "source": [
        "from pymorphy2 import MorphAnalyzer\n",
        "morph = MorphAnalyzer()"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "50M_ph1YLZTg"
      },
      "source": [
        "from collections import Counter"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZihF8uk_VHVs"
      },
      "source": [
        "from collections import OrderedDict"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IxzeaRAOchrt"
      },
      "source": [
        "import json"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hcev27qovCAM"
      },
      "source": [
        "from sklearn.metrics import accuracy_score"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FQofAbh1xoM5"
      },
      "source": [
        "from pprint import pprint"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6JoXLWkRIdcL"
      },
      "source": [
        "with open('pos_rev.txt', 'r', encoding='utf-8') as p:\n",
        "    pos_r = p.read()"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0u45LSFBIE6G"
      },
      "source": [
        "with open('neg_rev.txt', 'r', encoding='utf-8') as n:\n",
        "    neg_r = n.read()"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "raCA0fmFMpNQ"
      },
      "source": [
        "### 2. *Токенизируйте слова, приведите их к нижнему регистру и к начальной форме (1 балл за токенизацию, 1 - за начальную форму)*\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AJEo1xDwNCAX"
      },
      "source": [
        "def collect_normform(text): # приводим слова к нижнему регистру и начальной форме\n",
        "    words = []\n",
        "    for word in nltk.word_tokenize(text.lower()):\n",
        "        if word.isalpha():\n",
        "            words.append(morph.parse(word)[0].normal_form)\n",
        "    return words"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AyntpArRLOGA"
      },
      "source": [
        "n_normform = collect_normform(neg_r)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FAhc5yrtL8F3"
      },
      "source": [
        "p_normform = collect_normform(pos_r)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mTZATqT-MsgQ"
      },
      "source": [
        "### 3. Составьте 2 множества - в одном будут слова, которые встречаются **только** в положительных отзывах, а в другом - встречающиеся **только** в отрицательных. Попробуйте поиграть с частотностями и исключить шум (к примеру, выбросить слова, встречающиеся 1-2 раза) (3 балла) (если у вас получились пустые множества, уберите фильтр по частотности или увеличьте выборку)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fTJ5u4vhMuMR"
      },
      "source": [
        "def compare_lists(n_list, p_list, max_len=65): \n",
        "  #составляем множества со словами только из положительных и только из отрицательных отзывов\n",
        "  freqlist_n = Counter()\n",
        "  freqlist_p = Counter()\n",
        "  for n in n_list:\n",
        "    if n not in p_list:\n",
        "      freqlist_n[n] += 1\n",
        "  for p in p_list:\n",
        "    if p not in n_list:\n",
        "      freqlist_p[p] += 1\n",
        "  return dict(freqlist_n.most_common(max_len)), dict(freqlist_p.most_common(max_len))"
      ],
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qmh_X0skTBmN"
      },
      "source": [
        "freqlist_n, freqlist_p = compare_lists(n_normform, p_normform)"
      ],
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z2Tt7fFhY8Ls"
      },
      "source": [
        "freq_lists = {} #объединяем в один словарь\n",
        "freq_lists['pos'] = freqlist_p\n",
        "freq_lists['neg'] = freqlist_n"
      ],
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZFcl2eAd7KhS",
        "outputId": "cd449111-ec3d-4f50-c937-80cd3b6e9242",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "OrderedDict(freqlist_n)"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OrderedDict([('мультфильм', 10),\n",
              "             ('помощь', 8),\n",
              "             ('попытаться', 7),\n",
              "             ('касса', 6),\n",
              "             ('пафосный', 6),\n",
              "             ('матрица', 6),\n",
              "             ('очевидный', 5),\n",
              "             ('тяжёлый', 5),\n",
              "             ('медицина', 5),\n",
              "             ('непонятно', 5),\n",
              "             ('парень', 5),\n",
              "             ('даррелла', 5),\n",
              "             ('награда', 5),\n",
              "             ('косичка', 5),\n",
              "             ('облик', 4),\n",
              "             ('физический', 4),\n",
              "             ('осознавать', 4),\n",
              "             ('предназначить', 4),\n",
              "             ('воля', 4),\n",
              "             ('симпатия', 4),\n",
              "             ('попытка', 4),\n",
              "             ('никак', 4),\n",
              "             ('влюбляться', 4),\n",
              "             ('потратить', 4),\n",
              "             ('способность', 4),\n",
              "             ('спорить', 4),\n",
              "             ('сотня', 4),\n",
              "             ('преподносить', 4),\n",
              "             ('основа', 4),\n",
              "             ('костнера', 4),\n",
              "             ('состояние', 4),\n",
              "             ('отдать', 4),\n",
              "             ('очевидно', 4),\n",
              "             ('убить', 4),\n",
              "             ('девушка', 4),\n",
              "             ('ясно', 4),\n",
              "             ('неплохо', 4),\n",
              "             ('вовсе', 4),\n",
              "             ('избранный', 4),\n",
              "             ('приём', 4),\n",
              "             ('посредственный', 4),\n",
              "             ('веление', 4),\n",
              "             ('кристалл', 4),\n",
              "             ('нету', 4),\n",
              "             ('переносить', 3),\n",
              "             ('нисхождение', 3),\n",
              "             ('явление', 3),\n",
              "             ('случайно', 3),\n",
              "             ('зрелищность', 3),\n",
              "             ('бессмертие', 3),\n",
              "             ('толпа', 3),\n",
              "             ('помогать', 3),\n",
              "             ('священный', 3),\n",
              "             ('досмотреть', 3),\n",
              "             ('касаться', 3),\n",
              "             ('загадка', 3),\n",
              "             ('самурай', 3),\n",
              "             ('отсутствие', 3),\n",
              "             ('двигаться', 3),\n",
              "             ('особь', 3),\n",
              "             ('сопереживать', 3),\n",
              "             ('литература', 3),\n",
              "             ('ответить', 3),\n",
              "             ('уйти', 3),\n",
              "             ('всяческий', 3)])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zGwI_xfDMucY"
      },
      "source": [
        "\n",
        "### 4. Создайте функцию, которая будет определять, положительный ли отзыв или отрицательный в зависимости от того, какие слова встретились в нём, и посчитайте качество при помощи accuracy (1 - за коректно работающую функцию, 1 - за подсчёт accuracy)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oa_uzdUjMv9u"
      },
      "source": [
        "test_reviews = json.load(open(\"test_r.json\")) # открываем словарь с тестовыми текстами"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_zs2PfiRdN3e"
      },
      "source": [
        "pprint(test_reviews)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OIs816s4hZg-"
      },
      "source": [
        "def ton_detect(freq_lists, text): \n",
        "    counts = Counter()\n",
        "    for tone, freq_list in freq_lists.items():\n",
        "        freq_list = Counter(freq_list)\n",
        "        for word in nltk.word_tokenize(text):\n",
        "          morph.parse(word)[0].normal_form\n",
        "          counts[tone] += int(freq_list[word] > 0)\n",
        "    return counts.most_common()"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CFjcmwPSt8vC",
        "outputId": "cc49d1a4-04c1-46eb-eb28-d7c451e39c24",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        }
      },
      "source": [
        "for review, tone in test_reviews.items():\n",
        "  counts = ton_detect(freq_lists, review)\n",
        "  print(counts, tone)"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('pos', 0), ('neg', 0)] pos\n",
            "[('pos', 3), ('neg', 2)] pos\n",
            "[('pos', 5), ('neg', 3)] pos\n",
            "[('pos', 2), ('neg', 1)] pos\n",
            "[('pos', 1), ('neg', 1)] pos\n",
            "[('neg', 5), ('pos', 0)] neg\n",
            "[('pos', 1), ('neg', 0)] neg\n",
            "[('neg', 2), ('pos', 1)] neg\n",
            "[('pos', 1), ('neg', 1)] neg\n",
            "[('neg', 2), ('pos', 0)] neg\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fTwTd_Exutpj"
      },
      "source": [
        "### Считаем accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "USSA5LT1utF6"
      },
      "source": [
        "def test_tone_detect(freq_lists, reviews_dict):\n",
        "    results = [] \n",
        "    gold = []     \n",
        "    \n",
        "    for text, tone in reviews_dict.items():\n",
        "      predicted_tone = ton_detect(freq_lists, text)[0][0]\n",
        "      results.append(predicted_tone)\n",
        "      gold.append(tone)\n",
        "    print(\"Результаты:\")\n",
        "    print(\"Accuracy: %.4f\" % accuracy_score(results, gold))"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DijqZnWdz9f7",
        "outputId": "59ab381d-f6f0-4951-ce58-55304ddfcd85",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "test_tone_detect(freq_lists, test_reviews)"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "RESULTS:\n",
            "Test size: 5 texts per tone\n",
            "Accuracy: 0.8000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Bw9tfrpgKr-"
      },
      "source": [
        "Сначала accuracy была 0.6, и пишлось поиграть с длинной словарей, чтобы увеличить ее."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NsiOu9wV49MI"
      },
      "source": [
        "Как улучшить:\n",
        "Во-первых, собрать больше отзывов. \n",
        "\n",
        "Во-вторых, можно составлять словарь из словосочетаний, а не из слов. "
      ]
    }
  ]
}