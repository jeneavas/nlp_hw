{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "hw2.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F1yhCWc-Gjxm"
      },
      "source": [
        "#####1. Создание текстов, разметка, объяснение что в них сложного."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ddkFBaQfVvI-"
      },
      "source": [
        "Обработаем текст с помощью pymorphy, чтобы не делать все руками\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wHNgnensDbap",
        "outputId": "468dc05b-e627-4d46-d9a6-5e4e4f986140",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        }
      },
      "source": [
        "pip install pymorphy2"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pymorphy2 in /usr/local/lib/python3.6/dist-packages (0.9.1)\n",
            "Requirement already satisfied: pymorphy2-dicts-ru<3.0,>=2.4 in /usr/local/lib/python3.6/dist-packages (from pymorphy2) (2.4.417127.4579844)\n",
            "Requirement already satisfied: dawg-python>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from pymorphy2) (0.7.2)\n",
            "Requirement already satisfied: docopt>=0.6 in /usr/local/lib/python3.6/dist-packages (from pymorphy2) (0.6.2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TAtHxDpYZ3aR"
      },
      "source": [
        "from pymorphy2 import MorphAnalyzer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iWdxU9ChHte-"
      },
      "source": [
        "from pymorphy2.tokenizers import simple_word_tokenize"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FONCZE7SZ_SW"
      },
      "source": [
        "m = MorphAnalyzer()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ayWX1ag7HxQf"
      },
      "source": [
        "text_rus = '''Данные занимают слишком много места. Старинная печь быстро греется\n",
        " и долго остывает. Фабричный простой влечет потерю прибыли. Очередная напасть \n",
        " постигла главного героя. Ксения Собчак очень долго хейтила Анастасию Волочкову.\n",
        "  Из-за шкафа выглянул домовой. Преподаватель прекрасно говорил по-французски.\n",
        "  Нью-Йорк – это не столица США. Убегая с бала, Золушка потеряла хрустальную туфельку.\n",
        "  Он просто ответил: «не-а». По-моему, наш минор очень непонятный. \n",
        "  Многие стэнят Гарри Стайлса. Она снова вкрашилась в мальчика из интернета. \n",
        "  Како-то он кринжовый. Окружающий мир – самый интересный предмет в школе. \n",
        "  См. стр. 128. Он еще долго улыбался. Мой дом находится вблизи железной дороги.\n",
        "   Вокруг нас высились голубые ели. Печь хорошо топить осиной.'''"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Q9mtbrzZY5g"
      },
      "source": [
        "Что сложного в этом тексте:\n",
        "1. частичные оминимы типа *печь*, часть речи которых без контекста угадать сложно\n",
        "2. сокращения, например см.\n",
        "3. аббревиатуры\n",
        "4. слова в тире"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "67PerA12H4aN"
      },
      "source": [
        "word_pos_pymorphy = []\n",
        "for token in simple_word_tokenize(text_rus):\n",
        "  parsed = m.parse(token)[0]\n",
        "  word_pos_pymorphy.append((parsed.word, parsed.tag.POS))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PJEB9uQvV_d2"
      },
      "source": [
        "Испраивим то, что нам не нравится. Например, мы не будем разделять краткие и полные прилагательные, выделять личные местоимения в отельный класс, все местоимения обозначим как PRON\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rjYS6CTKa__1"
      },
      "source": [
        "gold_rus = [('данные', 'NOUN'),\n",
        " ('занимают', 'VERB'),\n",
        " ('слишком', 'ADV'),\n",
        " ('много', 'ADV'),\n",
        " ('места', 'NOUN'),\n",
        " ('.', None),\n",
        " ('старинная', 'ADJ'),\n",
        " ('печь', 'NOUN'),\n",
        " ('быстро', 'ADV'),\n",
        " ('греется', 'VERB'),\n",
        " ('и', 'CONJ'),\n",
        " ('долго', 'ADV'),\n",
        " ('остывает', 'VERB'),\n",
        " ('.', None),\n",
        " ('фабричный', 'ADJ'),\n",
        " ('простой', 'NOUN'),\n",
        " ('влечёт', 'VERB'),\n",
        " ('потерю', 'NOUN'),\n",
        " ('прибыли', 'NOUN'),\n",
        " ('.', None),\n",
        " ('очередная', 'ADJ'),\n",
        " ('напасть', 'NOUN'),\n",
        " ('постигла', 'VERB'),\n",
        " ('главного', 'ADJ'),\n",
        " ('героя', 'NOUN'),\n",
        " ('.', None),\n",
        " ('ксения', 'NOUN'),\n",
        " ('собчак', 'NOUN'),\n",
        " ('очень', 'ADV'),\n",
        " ('долго', 'ADV'),\n",
        " ('хейтила', 'VERB'),\n",
        " ('анастасию', 'NOUN'),\n",
        " ('волочкову', 'NOUN'),\n",
        " ('.', None),\n",
        " ('из-за', 'PREP'),\n",
        " ('шкафа', 'NOUN'),\n",
        " ('выглянул', 'VERB'),\n",
        " ('домовой', 'NOUN'),\n",
        " ('.', None),\n",
        " ('преподаватель', 'NOUN'),\n",
        " ('прекрасно', 'ADV'),\n",
        " ('говорил', 'VERB'),\n",
        " ('по-французски', 'ADV'),\n",
        " ('.', None),\n",
        " ('нью-йорк', 'NOUN'),\n",
        " ('–', None),\n",
        " ('это', 'PRCL'),\n",
        " ('не', 'PRCL'),\n",
        " ('столица', 'NOUN'),\n",
        " ('сша', 'NOUN'),\n",
        " ('.', None),\n",
        " ('убегая', 'GRND'),\n",
        " ('с', 'PREP'),\n",
        " ('бала', 'NOUN'),\n",
        " (',', None),\n",
        " ('золушка', 'NOUN'),\n",
        " ('потеряла', 'VERB'),\n",
        " ('хрустальную', 'ADJ'),\n",
        " ('туфельку', 'NOUN'),\n",
        " ('.', None),\n",
        " ('он', 'PRON'),\n",
        " ('просто', 'PRCL'),\n",
        " ('ответил', 'VERB'),\n",
        " (':', None),\n",
        " ('«', None),\n",
        " ('не-а', 'PRCL'),\n",
        " ('»', None),\n",
        " ('.', None),\n",
        " ('по-моему', 'ADV'),\n",
        " (',', None),\n",
        " ('наш', 'PRON'),\n",
        " ('минор', 'NOUN'),\n",
        " ('очень', 'ADV'),\n",
        " ('непонятный', 'ADJ'),\n",
        " ('.', None),\n",
        " ('многие', 'NOUN'),\n",
        " ('стэнят', 'VERB'),\n",
        " ('гарри', 'NOUN'),\n",
        " ('стайлса', 'NOUN'),\n",
        " ('.', None),\n",
        " ('она', 'PRONN'),\n",
        " ('снова', 'ADV'),\n",
        " ('вкрашилась', 'VERB'),\n",
        " ('в', 'PREP'),\n",
        " ('мальчика', 'NOUN'),\n",
        " ('из', 'PREP'),\n",
        " ('интернета', 'NOUN'),\n",
        " ('.', None),\n",
        " ('какой-то', 'PRON'),\n",
        " ('он', 'PRON'),\n",
        " ('кринжовый', 'ADJ'),\n",
        " ('.', None),\n",
        " ('окружающий', 'PRT'),\n",
        " ('мир', 'NOUN'),\n",
        " ('–', None),\n",
        " ('самый', 'PRON'),\n",
        " ('интересный', 'ADJ'),\n",
        " ('предмет', 'NOUN'),\n",
        " ('в', 'PREP'),\n",
        " ('школе', 'NOUN'),\n",
        " ('.', None),\n",
        " ('см', 'VERB'),\n",
        " ('.', None),\n",
        " ('стр', 'NOUN'),\n",
        " ('.', None),\n",
        " ('128', 'NUM'),\n",
        " ('.', None),\n",
        " ('он', 'PRON'),\n",
        " ('ещё', 'PRCL'),\n",
        " ('долго', 'ADV'),\n",
        " ('улыбался', 'VERB'),\n",
        " ('.', None),\n",
        " ('мой', 'PRON'),\n",
        " ('дом', 'NOUN'),\n",
        " ('находится', 'VERB'),\n",
        " ('вблизи', 'PREP'),\n",
        " ('железной', 'ADJ'),\n",
        " ('дороги', 'NOUN'),\n",
        " ('.', None),\n",
        " ('вокруг', 'PREP'),\n",
        " ('нас', 'NPRON'),\n",
        " ('высились', 'VERB'),\n",
        " ('голубые', 'ADJ'),\n",
        " ('ели', 'NOUN'),\n",
        " ('.', None),\n",
        " ('печь', 'NOUN'),\n",
        " ('хорошо', 'ADV'),\n",
        " ('топить', 'VERB'),\n",
        " ('осиной', 'NOUN'),\n",
        " ('.', None)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YCyue9bRbGuu"
      },
      "source": [
        "gold_word_pos"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mUTpTqtcWi0X"
      },
      "source": [
        "Теперь то же самое с английским текстом\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cSANQ4M9at1D"
      },
      "source": [
        "import spacy\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_sm\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CMyyG_VzEkVF"
      },
      "source": [
        "text_eng = '''Skiing is a fun winter activity. Becoming rich is the dream of \n",
        "many people. They aim to visit as much places as possible. A girl places her \n",
        "toy on the shelf. Her moves were graceful and precise. Love is what you love \n",
        "about her. She faces serious problems every time she gets out of bed. We should\n",
        "calculate mean of the group. Sum variables to see the right answer. This person\n",
        "knows everything about the kind tiger. My will will pass on. Express test for\n",
        "COVID-19 can be made only in hospital. You address this letter to the wrong person.'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uHpV3-baaP4R"
      },
      "source": [
        "Что сложного:\n",
        "1. те же частичные омонимы\n",
        "2. герундий\n",
        "3. aббревиатуры"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B8_7kfXJS89F"
      },
      "source": [
        "doc = nlp(text_eng)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ttaSs5Eede02"
      },
      "source": [
        "word_pos_spacy = []\n",
        "for s in doc.sents:\n",
        "  for t in s:\n",
        "    word_pos_spacy.append((t.text, t.pos_))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KK41nYILTkmV",
        "outputId": "c60bec73-aa9d-4848-ac60-b72efdae31ce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "word_pos_spacy"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Skiing', 'NOUN'),\n",
              " ('is', 'AUX'),\n",
              " ('a', 'DET'),\n",
              " ('fun', 'ADJ'),\n",
              " ('winter', 'NOUN'),\n",
              " ('activity', 'NOUN'),\n",
              " ('.', 'PUNCT'),\n",
              " ('Becoming', 'VERB'),\n",
              " ('rich', 'ADJ'),\n",
              " ('is', 'AUX'),\n",
              " ('the', 'DET'),\n",
              " ('dream', 'NOUN'),\n",
              " ('of', 'ADP'),\n",
              " ('many', 'ADJ'),\n",
              " ('people', 'NOUN'),\n",
              " ('.', 'PUNCT'),\n",
              " ('They', 'PRON'),\n",
              " ('aim', 'VERB'),\n",
              " ('to', 'PART'),\n",
              " ('visit', 'VERB'),\n",
              " ('as', 'SCONJ'),\n",
              " ('much', 'ADJ'),\n",
              " ('places', 'NOUN'),\n",
              " ('as', 'SCONJ'),\n",
              " ('possible', 'ADJ'),\n",
              " ('.', 'PUNCT'),\n",
              " ('A', 'DET'),\n",
              " ('girl', 'NOUN'),\n",
              " ('places', 'VERB'),\n",
              " ('her', 'DET'),\n",
              " ('toy', 'NOUN'),\n",
              " ('on', 'ADP'),\n",
              " ('the', 'DET'),\n",
              " ('shelf', 'NOUN'),\n",
              " ('.', 'PUNCT'),\n",
              " ('Her', 'DET'),\n",
              " ('moves', 'NOUN'),\n",
              " ('were', 'AUX'),\n",
              " ('graceful', 'ADJ'),\n",
              " ('and', 'CCONJ'),\n",
              " ('precise', 'ADJ'),\n",
              " ('.', 'PUNCT'),\n",
              " ('Love', 'NOUN'),\n",
              " ('is', 'AUX'),\n",
              " ('what', 'PRON'),\n",
              " ('you', 'PRON'),\n",
              " ('love', 'VERB'),\n",
              " ('about', 'ADP'),\n",
              " ('her', 'PRON'),\n",
              " ('.', 'PUNCT'),\n",
              " ('She', 'PRON'),\n",
              " ('faces', 'VERB'),\n",
              " ('serious', 'ADJ'),\n",
              " ('problems', 'NOUN'),\n",
              " ('every', 'DET'),\n",
              " ('time', 'NOUN'),\n",
              " ('she', 'PRON'),\n",
              " ('gets', 'VERB'),\n",
              " ('out', 'SCONJ'),\n",
              " ('of', 'ADP'),\n",
              " ('bed', 'NOUN'),\n",
              " ('.', 'PUNCT'),\n",
              " ('We', 'PRON'),\n",
              " ('should', 'VERB'),\n",
              " ('calculate', 'VERB'),\n",
              " ('mean', 'NOUN'),\n",
              " ('of', 'ADP'),\n",
              " ('the', 'DET'),\n",
              " ('group', 'NOUN'),\n",
              " ('.', 'PUNCT'),\n",
              " ('Sum', 'NOUN'),\n",
              " ('variables', 'NOUN'),\n",
              " ('to', 'PART'),\n",
              " ('see', 'VERB'),\n",
              " ('the', 'DET'),\n",
              " ('right', 'ADJ'),\n",
              " ('answer', 'NOUN'),\n",
              " ('.', 'PUNCT'),\n",
              " ('This', 'DET'),\n",
              " ('person', 'NOUN'),\n",
              " ('knows', 'VERB'),\n",
              " ('everything', 'PRON'),\n",
              " ('about', 'ADP'),\n",
              " ('the', 'DET'),\n",
              " ('kind', 'ADJ'),\n",
              " ('tiger', 'NOUN'),\n",
              " ('.', 'PUNCT'),\n",
              " ('My', 'DET'),\n",
              " ('will', 'NOUN'),\n",
              " ('will', 'VERB'),\n",
              " ('pass', 'VERB'),\n",
              " ('on', 'ADP'),\n",
              " ('.', 'PUNCT'),\n",
              " ('Express', 'ADJ'),\n",
              " ('test', 'NOUN'),\n",
              " ('for', 'ADP'),\n",
              " ('COVID-19', 'NOUN'),\n",
              " ('can', 'VERB'),\n",
              " ('be', 'AUX'),\n",
              " ('made', 'VERB'),\n",
              " ('only', 'ADV'),\n",
              " ('in', 'ADP'),\n",
              " ('hospital', 'NOUN'),\n",
              " ('.', 'PUNCT'),\n",
              " ('You', 'PRON'),\n",
              " ('address', 'VERB'),\n",
              " ('this', 'DET'),\n",
              " ('letter', 'NOUN'),\n",
              " ('to', 'ADP'),\n",
              " ('the', 'DET'),\n",
              " ('wrong', 'ADJ'),\n",
              " ('person', 'NOUN'),\n",
              " ('.', 'PUNCT')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 309
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xBcAtnqzHp4p"
      },
      "source": [
        "gold_eng = [('Skiing', 'NOUN'),\n",
        " ('is', 'VERB'),\n",
        " ('a', 'DET'),\n",
        " ('fun', 'ADJ'),\n",
        " ('winter', 'ADJ'),\n",
        " ('activity', 'NOUN'),\n",
        " ('.', 'PUNCT'),\n",
        " ('Becoming', 'NOUN'),\n",
        " ('rich', 'ADJ'),\n",
        " ('is', 'VERB'),\n",
        " ('the', 'DET'),\n",
        " ('dream', 'NOUN'),\n",
        " ('of', 'ADP'),\n",
        " ('many', 'ADJ'),\n",
        " ('people', 'NOUN'),\n",
        " ('.', 'PUNCT'),\n",
        " ('They', 'PRON'),\n",
        " ('aim', 'VERB'),\n",
        " ('to', 'PART'),\n",
        " ('visit', 'VERB'),\n",
        " ('as', 'CONJ'),\n",
        " ('much', 'ADJ'),\n",
        " ('places', 'NOUN'),\n",
        " ('as', 'CONJ'),\n",
        " ('possible', 'ADJ'),\n",
        " ('.', 'PUNCT'),\n",
        " ('A', 'DET'),\n",
        " ('girl', 'NOUN'),\n",
        " ('places', 'VERB'),\n",
        " ('her', 'DET'),\n",
        " ('toy', 'NOUN'),\n",
        " ('on', 'ADP'),\n",
        " ('the', 'DET'),\n",
        " ('shelf', 'NOUN'),\n",
        " ('.', 'PUNCT'),\n",
        " ('Her', 'DET'),\n",
        " ('moves', 'NOUN'),\n",
        " ('were', 'VERB'),\n",
        " ('graceful', 'ADJ'),\n",
        " ('and', 'CONJ'),\n",
        " ('precise', 'ADJ'),\n",
        " ('.', 'PUNCT'),\n",
        " ('Love', 'NOUN'),\n",
        " ('is', 'VERB'),\n",
        " ('what', 'PRON'),\n",
        " ('you', 'PRON'),\n",
        " ('love', 'VERB'),\n",
        " ('about', 'ADP'),\n",
        " ('her', 'PRON'),\n",
        " ('.', 'PUNCT'),\n",
        " ('She', 'PRON'),\n",
        " ('faces', 'VERB'),\n",
        " ('serious', 'ADJ'),\n",
        " ('problems', 'NOUN'),\n",
        " ('every', 'DET'),\n",
        " ('time', 'NOUN'),\n",
        " ('she', 'PRON'),\n",
        " ('gets', 'VERB'),\n",
        " ('out', 'CONJ'),\n",
        " ('of', 'ADP'),\n",
        " ('bed', 'NOUN'),\n",
        " ('.', 'PUNCT'),\n",
        " ('We', 'PRON'),\n",
        " ('should', 'VERB'),\n",
        " ('calculate', 'VERB'),\n",
        " ('mean', 'NOUN'),\n",
        " ('of', 'ADP'),\n",
        " ('the', 'DET'),\n",
        " ('group', 'NOUN'),\n",
        " ('.', 'PUNCT'),\n",
        " ('Sum', 'VERB'),\n",
        " ('variables', 'NOUN'),\n",
        " ('to', 'PART'),\n",
        " ('see', 'VERB'),\n",
        " ('the', 'DET'),\n",
        " ('right', 'ADJ'),\n",
        " ('answer', 'NOUN'),\n",
        " ('.', 'PUNCT'),\n",
        " ('This', 'DET'),\n",
        " ('person', 'NOUN'),\n",
        " ('knows', 'VERB'),\n",
        " ('everything', 'PRON'),\n",
        " ('about', 'ADP'),\n",
        " ('the', 'DET'),\n",
        " ('kind', 'ADJ'),\n",
        " ('tiger', 'NOUN'),\n",
        " ('.', 'PUNCT'),\n",
        " ('My', 'DET'),\n",
        " ('will', 'NOUN'),\n",
        " ('will', 'VERB'),\n",
        " ('pass', 'VERB'),\n",
        " ('on', 'ADP'),\n",
        " ('.', 'PUNCT'),\n",
        " ('Express', 'ADJ'),\n",
        " ('test', 'NOUN'),\n",
        " ('for', 'ADP'),\n",
        " ('COVID-19', 'NOUN'),\n",
        " ('can', 'VERB'),\n",
        " ('be', 'VERB'),\n",
        " ('made', 'VERB'),\n",
        " ('only', 'ADV'),\n",
        " ('in', 'ADP'),\n",
        " ('hospital', 'NOUN'),\n",
        " ('.', 'PUNCT'),\n",
        " ('You', 'PRON'),\n",
        " ('address', 'VERB'),\n",
        " ('this', 'DET'),\n",
        " ('letter', 'NOUN'),\n",
        " ('to', 'ADP'),\n",
        " ('the', 'DET'),\n",
        " ('wrong', 'ADJ'),\n",
        " ('person', 'NOUN'),\n",
        " ('.', 'PUNCT')]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n2D7G5vhbVZU"
      },
      "source": [
        "##2. Для русского (pymorphy2, mysteam, Natasha), для английского (SpyCy, Flair, NLTK) \n",
        "\n",
        "* Разметка \n",
        "* приведение к одному виду\n",
        "* подсчет accuracy\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "INEQW64lU5bS"
      },
      "source": [
        "### русский"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kGkdYkmaVGtJ"
      },
      "source": [
        "####pymorphy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6bE2BJl7VJcL"
      },
      "source": [
        "word_pos_pymorphy # разбор уже сделан в перовм пункте"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0KbjEqr8XAUg"
      },
      "source": [
        "####mysteam"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HlMbhijcXADN",
        "outputId": "2f973e4b-ee31-4a78-97a3-3236080d170c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "from pymystem3 import Mystem\n",
        "m = Mystem()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Installing mystem to /root/.local/bin/mystem from http://download.cdn.yandex.net/mystem/mystem-3.1-linux-64bit.tar.gz\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MGl4a2qjXm4e"
      },
      "source": [
        "ana = m.analyze(text_rus) \n",
        "pprint(ana[:20])\n",
        "# почему-то mysteam в колабе не работает, я сделала разбор в jupyter и сохранила в файл просто"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eKVUHFofrA0G"
      },
      "source": [
        "import json"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XMD0cG6RqpWF"
      },
      "source": [
        "ana = json.load(open(\"data.json\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zoaz7CvnrVz5"
      },
      "source": [
        "word_pos_mystem = []\n",
        "for a in ana:\n",
        "  if 'analysis' in a and a['analysis'] != []:\n",
        "    word_pos_mystem.append((a['text'], a['analysis'][0]['gr'].split('=')[0].split(',')[0]))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eR4M2EjZw9gT"
      },
      "source": [
        "word_pos_mystem"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mONnxw_jzRCP"
      },
      "source": [
        "#### Natasha"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "73nwfhC4zCRL"
      },
      "source": [
        "!pip install natasha"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mhPylgcTzw0a"
      },
      "source": [
        "from natasha import (\n",
        "    Segmenter,\n",
        "    MorphVocab,\n",
        "    \n",
        "    NewsEmbedding,\n",
        "    NewsMorphTagger,\n",
        "    NewsNERTagger,\n",
        "    \n",
        "    PER,\n",
        "    NamesExtractor,\n",
        "    Doc\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rqYyA4Fxz4GQ"
      },
      "source": [
        "segmenter = Segmenter()\n",
        "emb = NewsEmbedding()\n",
        "morph_tagger = NewsMorphTagger(emb)\n",
        "ner_tagger = NewsNERTagger(emb)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UXYyIQAn0F8J"
      },
      "source": [
        "doc = Doc(text_rus)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GbuDhJnb0QQb"
      },
      "source": [
        "doc.segment(segmenter)\n",
        "doc.tag_morph(morph_tagger)\n",
        "display(doc.tokens[:5])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZZGrI79LBXDh"
      },
      "source": [
        "doc.sents[0].morph.tokens[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sAMvtOouDTBR"
      },
      "source": [
        "word_pos_natasha = []\n",
        "for s in doc.sents:\n",
        "  for w in s.morph.tokens:\n",
        "    word_pos_natasha.append((w.text, w.pos))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A4vo1JO6EE9_"
      },
      "source": [
        "word_pos_natasha"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "byr0-LjbXAYn"
      },
      "source": [
        "###английский"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IQ_J6xHmFsQI"
      },
      "source": [
        "#### flair"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OK3o_rY6i3Q1"
      },
      "source": [
        "! pip install flair"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mVxUXme5iwWw"
      },
      "source": [
        "from flair.data import Sentence\n",
        "from flair.models import SequenceTagger"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AT9kkwngiyZs",
        "outputId": "e8695e07-afe5-46da-8f58-7a9d374eef59",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "sentence = Sentence(text_eng)\n",
        "\n",
        "tagger = SequenceTagger.load('pos')\n",
        "tagger.predict(sentence)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-10-12 18:42:39,056 loading file /root/.flair/models/en-pos-ontonotes-v0.5.pt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r0ZdXIz6F8a_"
      },
      "source": [
        "sent = sentence.to_tagged_string()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5RnTBby0Gaa8"
      },
      "source": [
        "sent_list = sent.split()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pTq5FlHPJu7p",
        "outputId": "7d47e098-8bc1-4235-e39a-7dd3cc65fc62",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "len(sent_list[0::2])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "115"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tXAEHffcHddP"
      },
      "source": [
        "word_pos_flair = []\n",
        "for word, pos in zip(sent_list[0::2], sent_list[1::2]):\n",
        "  word_pos_flair.append((word, pos.replace('<','').replace('>','')))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vWDqgOvNKEX5",
        "outputId": "ce65b798-85c0-4f47-f731-7ffb489273d1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "word_pos_flair"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Skiing', 'NN'),\n",
              " ('is', 'VBZ'),\n",
              " ('a', 'DT'),\n",
              " ('fun', 'JJ'),\n",
              " ('winter', 'NN'),\n",
              " ('activity', 'NN'),\n",
              " ('.', '.'),\n",
              " ('Becoming', 'VBG'),\n",
              " ('rich', 'JJ'),\n",
              " ('is', 'VBZ'),\n",
              " ('the', 'DT'),\n",
              " ('dream', 'NN'),\n",
              " ('of', 'IN'),\n",
              " ('many', 'JJ'),\n",
              " ('people', 'NNS'),\n",
              " ('.', ','),\n",
              " ('They', 'PRP'),\n",
              " ('aim', 'VBP'),\n",
              " ('to', 'TO'),\n",
              " ('visit', 'VB'),\n",
              " ('as', 'RB'),\n",
              " ('much', 'JJ'),\n",
              " ('places', 'NNS'),\n",
              " ('as', 'IN'),\n",
              " ('possible', 'JJ'),\n",
              " ('.', '.'),\n",
              " ('A', 'DT'),\n",
              " ('girl', 'NN'),\n",
              " ('places', 'VBZ'),\n",
              " ('her', 'PRP$'),\n",
              " ('toy', 'NN'),\n",
              " ('on', 'IN'),\n",
              " ('the', 'DT'),\n",
              " ('shelf', 'NN'),\n",
              " ('.', '.'),\n",
              " ('Her', 'PRP$'),\n",
              " ('moves', 'NNS'),\n",
              " ('were', 'VBD'),\n",
              " ('graceful', 'JJ'),\n",
              " ('and', 'CC'),\n",
              " ('precise', 'JJ'),\n",
              " ('.', '.'),\n",
              " ('Love', 'NN'),\n",
              " ('is', 'VBZ'),\n",
              " ('what', 'WP'),\n",
              " ('you', 'PRP'),\n",
              " ('love', 'VBP'),\n",
              " ('about', 'IN'),\n",
              " ('her', 'PRP'),\n",
              " ('.', '.'),\n",
              " ('She', 'PRP'),\n",
              " ('faces', 'VBZ'),\n",
              " ('serious', 'JJ'),\n",
              " ('problems', 'NNS'),\n",
              " ('every', 'DT'),\n",
              " ('time', 'NN'),\n",
              " ('she', 'PRP'),\n",
              " ('gets', 'VBZ'),\n",
              " ('out', 'IN'),\n",
              " ('of', 'IN'),\n",
              " ('bed', 'NN'),\n",
              " ('.', ','),\n",
              " ('We', 'PRP'),\n",
              " ('should', 'MD'),\n",
              " ('calculate', 'VB'),\n",
              " ('mean', 'NN'),\n",
              " ('of', 'IN'),\n",
              " ('the', 'DT'),\n",
              " ('group', 'NN'),\n",
              " ('.', '.'),\n",
              " ('Sum', 'NN'),\n",
              " ('variables', 'NNS'),\n",
              " ('to', 'TO'),\n",
              " ('see', 'VB'),\n",
              " ('the', 'DT'),\n",
              " ('right', 'JJ'),\n",
              " ('answer', 'NN'),\n",
              " ('.', ','),\n",
              " ('This', 'DT'),\n",
              " ('person', 'NN'),\n",
              " ('knows', 'VBZ'),\n",
              " ('everything', 'NN'),\n",
              " ('about', 'IN'),\n",
              " ('the', 'DT'),\n",
              " ('kind', 'NN'),\n",
              " ('tiger', 'NN'),\n",
              " ('.', '.'),\n",
              " ('My', 'PRP$'),\n",
              " ('will', 'NN'),\n",
              " ('will', 'MD'),\n",
              " ('pass', 'VB'),\n",
              " ('on', 'IN'),\n",
              " ('.', ','),\n",
              " ('Express', 'JJ'),\n",
              " ('test', 'NN'),\n",
              " ('for', 'IN'),\n",
              " ('COVID-19', 'NN'),\n",
              " ('can', 'MD'),\n",
              " ('be', 'VB'),\n",
              " ('made', 'VBN'),\n",
              " ('only', 'RB'),\n",
              " ('in', 'IN'),\n",
              " ('hospital', 'NN'),\n",
              " ('.', ','),\n",
              " ('You', 'PRP'),\n",
              " ('address', 'VBP'),\n",
              " ('this', 'DT'),\n",
              " ('letter', 'NN'),\n",
              " ('to', 'IN'),\n",
              " ('the', 'DT'),\n",
              " ('wrong', 'JJ'),\n",
              " ('person', 'NN'),\n",
              " ('.', '.')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 315
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XkTxfeU2F-Wj"
      },
      "source": [
        "#### NLTK"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CMwv7VDzoeL-",
        "outputId": "49fa8285-61dc-4a48-98e3-85c381831624",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "pip install nltk"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.6/dist-packages (3.2.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from nltk) (1.15.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ln4bEBYckF4O",
        "outputId": "c6dd375b-bdc4-4040-8b98-0e794dd682ee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "from nltk.tokenize import word_tokenize"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b7B0_vdhjtLR"
      },
      "source": [
        "text = word_tokenize(text_eng)\n",
        "word_pos_nltk = nltk.pos_tag(text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2aXeE9tcL1P-"
      },
      "source": [
        "#### Spacy\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g6n664QfL0OR",
        "outputId": "0fe8927d-169f-4595-b686-d1ffa61082b4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "word_pos_spacy # это мы уже сделали в первом пункте"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Skiing', 'NOUN'),\n",
              " ('is', 'AUX'),\n",
              " ('a', 'DET'),\n",
              " ('fun', 'ADJ'),\n",
              " ('winter', 'NOUN'),\n",
              " ('activity', 'NOUN'),\n",
              " ('.', 'PUNCT'),\n",
              " ('Becoming', 'VERB'),\n",
              " ('rich', 'ADJ'),\n",
              " ('is', 'AUX'),\n",
              " ('the', 'DET'),\n",
              " ('dream', 'NOUN'),\n",
              " ('of', 'ADP'),\n",
              " ('many', 'ADJ'),\n",
              " ('people', 'NOUN'),\n",
              " ('.', 'PUNCT'),\n",
              " ('They', 'PRON'),\n",
              " ('aim', 'VERB'),\n",
              " ('to', 'PART'),\n",
              " ('visit', 'VERB'),\n",
              " ('as', 'SCONJ'),\n",
              " ('much', 'ADJ'),\n",
              " ('places', 'NOUN'),\n",
              " ('as', 'SCONJ'),\n",
              " ('possible', 'ADJ'),\n",
              " ('.', 'PUNCT'),\n",
              " ('A', 'DET'),\n",
              " ('girl', 'NOUN'),\n",
              " ('places', 'VERB'),\n",
              " ('her', 'DET'),\n",
              " ('tall', 'ADJ'),\n",
              " ('on', 'ADP'),\n",
              " ('the', 'DET'),\n",
              " ('shelf', 'NOUN'),\n",
              " ('.', 'PUNCT'),\n",
              " ('Her', 'DET'),\n",
              " ('moves', 'NOUN'),\n",
              " ('were', 'AUX'),\n",
              " ('graceful', 'ADJ'),\n",
              " ('and', 'CCONJ'),\n",
              " ('precise', 'ADJ'),\n",
              " ('.', 'PUNCT'),\n",
              " ('Love', 'NOUN'),\n",
              " ('is', 'AUX'),\n",
              " ('what', 'PRON'),\n",
              " ('you', 'PRON'),\n",
              " ('love', 'VERB'),\n",
              " ('about', 'ADP'),\n",
              " ('her', 'PRON'),\n",
              " ('.', 'PUNCT'),\n",
              " ('She', 'PRON'),\n",
              " ('faces', 'VERB'),\n",
              " ('serious', 'ADJ'),\n",
              " ('problems', 'NOUN'),\n",
              " ('every', 'DET'),\n",
              " ('time', 'NOUN'),\n",
              " ('she', 'PRON'),\n",
              " ('gets', 'VERB'),\n",
              " ('out', 'SCONJ'),\n",
              " ('of', 'ADP'),\n",
              " ('bed', 'NOUN'),\n",
              " ('.', 'PUNCT'),\n",
              " ('We', 'PRON'),\n",
              " ('should', 'VERB'),\n",
              " ('calculate', 'VERB'),\n",
              " ('mean', 'NOUN'),\n",
              " ('of', 'ADP'),\n",
              " ('the', 'DET'),\n",
              " ('group', 'NOUN'),\n",
              " ('.', 'PUNCT'),\n",
              " ('Sum', 'NOUN'),\n",
              " ('variables', 'NOUN'),\n",
              " ('to', 'PART'),\n",
              " ('see', 'VERB'),\n",
              " ('the', 'DET'),\n",
              " ('right', 'ADJ'),\n",
              " ('answer', 'NOUN'),\n",
              " ('.', 'PUNCT'),\n",
              " ('This', 'DET'),\n",
              " ('person', 'NOUN'),\n",
              " ('does', 'AUX'),\n",
              " ('n’t', 'PART'),\n",
              " ('know', 'VERB'),\n",
              " ('anything', 'PRON'),\n",
              " ('about', 'ADP'),\n",
              " ('the', 'DET'),\n",
              " ('kind', 'ADJ'),\n",
              " ('tiger', 'NOUN'),\n",
              " ('.', 'PUNCT'),\n",
              " ('My', 'DET'),\n",
              " ('will', 'NOUN'),\n",
              " ('will', 'VERB'),\n",
              " ('pass', 'VERB'),\n",
              " ('on', 'ADP'),\n",
              " ('.', 'PUNCT'),\n",
              " ('Express', 'ADJ'),\n",
              " ('test', 'NOUN'),\n",
              " ('for', 'ADP'),\n",
              " ('COVID-19', 'NOUN'),\n",
              " ('can', 'VERB'),\n",
              " ('be', 'AUX'),\n",
              " ('made', 'VERB'),\n",
              " ('only', 'ADV'),\n",
              " ('in', 'ADP'),\n",
              " ('hospital', 'NOUN'),\n",
              " ('.', 'PUNCT'),\n",
              " ('You', 'PRON'),\n",
              " ('address', 'VERB'),\n",
              " ('this', 'DET'),\n",
              " ('letter', 'NOUN'),\n",
              " ('to', 'ADP'),\n",
              " ('the', 'DET'),\n",
              " ('wrong', 'ADJ'),\n",
              " ('person', 'NOUN'),\n",
              " ('.', 'PUNCT')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oQvn3tr2OP4m"
      },
      "source": [
        "## 3. Сравниваем парсеры"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nYv7NC4oL_ek"
      },
      "source": [
        "### приводим все к одному виду\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JtQPZaFTa7fh"
      },
      "source": [
        "#собираем все встетимшиеся теги в словарь, где значениями будут наши теги\n",
        "tags= {\n",
        "    'S':'NOUN', 'NN':'NOUN', 'NNS':'NOUN', 'NNP':'NOUN', 'NNPS':'NOUN',\n",
        "    'NOUN':'NOUN', 'PROPN':'NOUN',\n",
        "    'V':'VERB', 'VBZ':'VERB', 'VBG':'VERB', 'VBN':'VERB', 'VBD':'VERB',\n",
        "    'VBP':'VERB', 'MD':'VERB', 'VB':'VERB', 'INFN':'VERB', 'GRND':'VERB',\n",
        "    'AUX':'VERB', 'VERB':'VERB', 'PRTF':'VERB',\n",
        "    'IN':'PREP', 'PR':'PREP', 'PREP':'PREP', 'ADP':'PREP',\n",
        "    'ADJF':'ADJ', 'ADJS':'ADJ', 'A':'ADJ', 'JJ':'ADJ', 'ADJ':'ADJ', \n",
        "    'PRP$':'PRON', 'PRP':'PRON', 'SPRO':'PRON', 'APRO':'PRON','PRON':'PRON',\n",
        "    'WP':'PRON', 'NPRO':'PRON',\n",
        "    'DT':'DET', 'DET':'DET',\n",
        "    'RB':'ADV', 'RBR':'ADV', 'RBS':'ADV', 'ADVB':'ADV', 'ADV':'ADV',\n",
        "    'CC':'CONJ', 'CCONJ':'CONJ', 'SCONJ':'CONJ', 'CONJ':'CONJ',\n",
        "    'PART':'PRCL', 'P':'PRCL', 'PRCL':'PRCL', 'TO':'PRCL',\n",
        "    'NUM':'NUM'\n",
        "    }"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u2hPK7eVLHAZ"
      },
      "source": [
        "def check(word_pos_list): # проверяем, все ли тэги мы написали в словарь, дописываем чего нехватает\n",
        "  for t in word_pos_list:\n",
        "    if str(t[1]) not in tags:\n",
        "      print(t[1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uMzGPISWxZ0e"
      },
      "source": [
        "def unify(word_pos_list):\n",
        "  unified = []\n",
        "  for t in word_pos_list:\n",
        "    if str(t[1]) in tags:\n",
        "        unified.append((t[0], tags[str(t[1])]))\n",
        "  return unified"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8bFDUhBLdVtA"
      },
      "source": [
        "spacy_uni = unify(word_pos_spacy)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Kjf11Cc3jW5"
      },
      "source": [
        "flair_uni = unify(word_pos_flair)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-pnNSh5m3vdg"
      },
      "source": [
        "nltk_uni = unify(word_pos_nltk)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sHX1usAv3nPB"
      },
      "source": [
        "natasha_uni = unify(word_pos_natasha)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oghh0hOx6QPV"
      },
      "source": [
        "mystem_uni = unify(word_pos_mystem)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7NBOb9OKH-dg"
      },
      "source": [
        "pymorphy_uni = unify(word_pos_pymorphy)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XYpVeKowMWch"
      },
      "source": [
        "### оцениваем accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K_mk7w9L4at3"
      },
      "source": [
        "from sklearn.metrics import accuracy_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TmQrWRCKDZGU"
      },
      "source": [
        "def accuracy_count(test, gold_w_p):\n",
        "  gold = []\n",
        "  results = []\n",
        "  for t in gold_w_p:\n",
        "    if t[1] is not None and t[1] != 'PUNCT' and t[1] != 'NUM':\n",
        "      gold.append(t[1])\n",
        "  for t in test:\n",
        "    results.append(t[1])\n",
        "  return accuracy_score(results, gold)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xxbdb62hMFlt",
        "outputId": "4ada708e-57fc-42a5-b092-6e6c5eadd7fc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "accuracy_count(pymorphy_uni, gold_rus)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.82"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 352
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "baoyP5vTMtDq",
        "outputId": "49d64b89-0645-4816-f9d0-46778d768144",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "accuracy_count(mystem_uni, gold_rus)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.69"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 353
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5v6vzR1iEgIT",
        "outputId": "615d0ea3-7a1e-4cd0-f854-54e2697565e8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# для наташи считаем отдельно, потому что у нее не только цифры\n",
        "# имеют тег NUM, а мы не считам в образцовом тексте цифры \n",
        "gold = []\n",
        "results = []\n",
        "for t in gold_rus:\n",
        "  if t[1] is not None and t[1] != 'PUNCT':\n",
        "    gold.append(t[1])   \n",
        "for t in natasha_uni:\n",
        "  results.append(t[1])\n",
        "print(round(accuracy_score(results, gold), 2))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.83\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "spWQ0yRdOhpH"
      },
      "source": [
        "Победила наташа!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-IJMRaN7MyzN",
        "outputId": "31b57e4d-7f59-472b-a522-b4901f27dd70",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "accuracy_count(flair_uni, gold_eng)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.77"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 355
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CaCD0nwgNPw7",
        "outputId": "30475331-ecda-467e-9723-4c5dee42f34c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "accuracy_count(nltk_uni, gold_eng)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.73"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 356
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E9wdh0AYNSya",
        "outputId": "8aa73847-1f41-4326-cdbd-a8b819a24788",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "accuracy_count(spacy_uni, gold_eng)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.85"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 357
        }
      ]
    }
  ]
}